index: hide
name: Screening and Prevention Studies
title: Levels of Evidence for Cancer Screening and Prevention Studies
lead: Information about how to weigh the strength of the evidence obtained in cancer screening and prevention research studies.

## Introduction
The PDQ Screening and Prevention Editorial Board summarizes its understanding of the level of the evidence for the magnitude of the effect (including absolute and relative risks) for both the benefits and the harms of implementing cancer screening and prevention interventions. The Editorial Board uses the term “Level of Evidence” to refer to the certainty of its estimate of the health effects of implementing the intervention in question.

Varying levels of evidence support each PDQ screening or prevention summary. Evidence that indicates, within a narrow range, the direction and magnitude of the effect on health outcomes is termed "solid" evidence. Evidence that allows an estimate of the direction and magnitude of the health outcomes within a broader range, but still allows a reasonably certain estimate, is termed “fair.” Evidence that allows either no estimate at all or only an estimate that is very broad is termed "inadequate".

The highest Level of Evidence (“solid”) is that obtained from several well-designed and well-conducted randomized controlled trials (RCTs) in generalizable settings with generalizable populations that report evidence about both benefits and harms. It is, however, not always practical to conduct such trials to address every question within the field of screening and prevention. Thus, the PDQ Editorial Board does consider “fair” evidence in estimating the benefits and harms of an intervention in the general population. When the evidence for the benefits and/or harms of an intervention is “inadequate,” the Board states this finding.

The PDQ Editorial Board evaluates evidence in 2 steps. The first step is to describe the evidence within 5 domains (see below); the second is to judge the overall “level” of evidence as “solid,” “fair,” or “inadequate.” The Board conducts the same process separately for potential benefits and potential harms of each intervention. The PDQ Editorial Board does not explicitly assess the “net benefit” (i.e., benefits minus harms) of interventions, nor does it make recommendations.

The question at issue for the Board is to determine the direction and magnitude of important health effects from introducing the intervention into the general population. This is a question of effectiveness rather than of efficacy only, and the Board seeks evidence about effectiveness as well as efficacy. When only efficacy evidence is available, the Board must judge the additional uncertainty involved with estimating the actual health impact of widespread implementation.

## Evaluation of Evidence

The two steps in evaluating evidence are described below.

I. Description of the Evidence (The PDQ Editorial Board uses the same process for benefits and harms; the “evidence” referred to is the evidence relevant for answering the question of the magnitude of the health effects of widespread implementation.)

### Domains

#### A. Study Design (evidence from the best studies available; ranked in descending order of strength)
1. Evidence obtained from randomized controlled trials (see below).
2. Evidence obtained from nonrandomized controlled trials.
3. Evidence obtained from cohort or case-control studies.
4. Evidence from ecologic and descriptive studies (e.g., international patterns studies, time series).
5. Opinions of respected authorities based on clinical experience, descriptive studies, or reports of expert committees.

#### B. Internal Validity: “Quality” of Execution Within the Study Design

The Editorial Board uses design-specific criteria within each research design to assess the internal validity of the evidence. At present the Board uses the criteria developed by the U.S. Preventive Services Task Force (see Table 3 in [1]). These criteria may be modified over time as needed.

#### C. Consistency (coherence)/Volume of the Evidence
- One study (small vs. large number of participants; agree vs. disagree).
- Multiple studies (small vs. large number of participants; agree vs. disagree).

#### D. Magnitude of Effects on Health Outcomes (both absolute and relative risks; as quantitative as possible; may vary for different populations)

- Small positive/negative magnitude (benefits/harms).
- Larger positive/negative magnitude (benefits/harms).

#### E. External Validity

- Extent to which the intervention can be applied to usual practice with the same effects as in efficacy studies.
- Effects among people in the general population, differences with study subjects.

### II. Assessment of the Evidence

#### A. The level of certainty (solid, fair, inadequate) of our understanding of the direction and magnitude of the health effects (both benefits and harms) of widespread implementation.

#### B. Example: Statement of Benefits

Option 1: "Based on [solid/fair] evidence, use of intervention X [among population Y, where appropriate] leads to a reduction/increase in (a specific benefit).” [In the Evidence of Benefit section, the actual evidence is detailed, including evidence and assessment of direction and magnitude of specific benefits.]

Option 2: "The evidence is inadequate to make a clear determination of benefit." (To be used when evidence is inadequate in amount or quality.) Alternative format depending on situation: "The evidence is inadequate to determine whether (preventive service) reduces (health problem) to a clinically or public health important degree." (Further explanation or clarification as needed.) Need to state for what outcome the evidence is inadequate; i.e., to assess a mortality effect.

#### C. Example: Statement of Harms
Option 1: “Based on [solid/fair] evidence, use of intervention X [among population Y] leads to a reduction/increase in (a specific harm).” [In the Evidence of Harm section, the actual evidence is detailed, including evidence and assessment of the direction and magnitude of specific harms.]

Option 2: "The evidence is inadequate to make a clear determination of benefit." (To be used when evidence is inadequate in amount or quality.) Alternative format depending on situation: "The evidence is inadequate to determine whether (preventive service) reduces (health problem) to a clinically or public health important degree." (Further explanation or clarification as needed.) Need to state for what outcome the evidence is inadequate; i.e., to assess a mortality effect.

### References
Harris RP, Helfand M, Woolf SH, et al.: Current methods of the US Preventive Services Task Force: a review of the process. Am J Prev Med 20 (3 Suppl): 21-35, 2001. [PUBMED Abstract]

## Notes on Quality Assessment

1. **Semantics**: One can think of the “level” of a body of evidence as the certainty of the assessment allowed from the evidence. This may also be considered as the “quality” of the evidence to address a specific question. Because the word “quality” can have other meanings (e.g., the extent to which individual studies meet given criteria), the Editorial Board prefers the word “level.”

2. **Certainty**: Certainty can be considered in several ways, one of which is to use the heuristic of the “confidence interval.” This “confidence interval” does not come from a statistical calculation, but is instead a “conceptual confidence interval” (CCI) representing the Editorial Board’s assessment of the range of values for direction and magnitude of the effect of the intervention that is consistent with the overall evidence. This CCI is seeking to answer an effectiveness question (not simply an efficacy question). The question at issue is:

What would the health effects be if the intervention were widely implemented in routine practice? Even well-conducted RCTs may not provide “good” evidence if they are not conducted in generalizable populations, using generalizable tests and treatments. The CCI for evidence based on RCTs conducted in highly selected populations might be wide rather than narrow (“fair” as opposed to “good”) unless there are reasons to believe the effects would be the same in the general population.

3. **Benefits**: Potential benefits include mortality reduction (and should note whether disease-specific or overall), improved quality of life, improved function, and reduced need for invasive procedures or interventions. If mortality reduction from an RCT is disease-specific with no trend toward overall mortality reduction, then the Editorial Board might consider the contribution of this disease-specific reduction to overall mortality to be less certain. As the question at issue is an all-cause mortality question, the CCI for a study of only disease-specific reduction without other indications of overall reduction may be considered wider than if there were indications of overall mortality reduction.

4. **Harms**: Harms may be considered in 3 categories:

a. Psychological (often from labeling or anxiety after a false-positive test or a diagnosis of an “intermediate” condition of no clinical importance).
b. Complications from diagnostic or monitoring tests (e.g., colonoscopy with perforation for a positive FOBT).
c. Complications or side effects from treatment, especially treatment from which there are no benefits (e.g., in the case of “overdiagnosis”).

5. **Extrapolation**: Estimates of the presence and magnitude of either benefits or harms may come from extrapolation from indirect evidence; the degree of extrapolation determines the CCI for each estimate. For example, evidence shows that screening for ovarian cancer results in many false-positive tests (due to the low prevalence of the disease) for which the workup is an invasive procedure. Other evidence could provide an estimate of the effects of the invasive workup, including not only complications but also the discomfort, anxiety, and time of reduced usual activity. The evidence, then, for the harms of screening is indirect (i.e., not from an RCT of screening) but would still provide at least “fair” evidence of harms (i.e., intermediate width CCI).

6. **Judgment**: Judgment is involved at several steps in this process, including the assessment of “quality” (internal validity), consistency/coherence, external validity, and the overall “level” of evidence. It is important in each case that the rationale and conclusion be as explicit and transparent as possible. The reasoning behind the judgment of the overall Level of Evidence should be stated clearly.
