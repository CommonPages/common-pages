index: hide

<div class="Citation">
    <div class="Citation-thumb CitationThumb-linked"  data-href="https://doi.org/10.1029/2010jd014963">
      <img src="https://static.claimspace.cloud/climate-study-static/refs/thumbs/9/Schaller_et_al_2011-thumb.png" />
    </div>

  <div class="Citation-body">
    <div class="Citation-text">Schaller, N and Mahlstein, I and Cermak, J and Knutti, R, 2011: Analyzing precipitation projections: A comparison of different approaches to climate model evaluation. <span class="Article-journal">Journal of Geophysical Research-Atmospheres, </span><span class="Article-volume">116, </span>D10118pp.</div>
    <div class="Citation-links">
      <div class="CitationLink" data-href="https://doi.org/10.1029/2010jd014963">
        <div class="CitationLink-icon CitationLink-Doi"></div>
        <div class="CitationLink-text">DOI</div>
      </div>
      <div class="CitationLink" data-href="https://scholar.google.com/scholar?q=10.1029/2010jd014963">
        <div class="CitationLink-icon CitationLink-Scholar"></div>
        <div class="CitationLink-text">Google Scholar</div>
      </div>
    </div>
  </div>
</div>

Complexity and resolution of global climate models are steadily increasing, yet the uncertainty of their projections remains large, particularly for precipitation. Given the impacts precipitation changes have on ecosystems, there is a need to reduce projection uncertainty by assessing the performance of climate models. A common way of evaluating models is to consider global maps of errors against observations for a range of variables. However, depending on the purpose, feature‐based metrics defined on a regional scale and for one variable may be more suitable to identify the most accurate models. We compare three different ways of ranking the CMIP3 climate models: errors in a broad range of climate variables, errors in global field of precipitation, and regional features of modeled precipitation in areas where pronounced future changes are expected. The same analysis is performed for temperature to identify potential differences between variables. The multimodel mean is found to outperform all single models in the global field‐based rankings but performs only averagely for the feature‐based ranking. Selecting the best models for each metric reduces the absolute spread in projections. If anomalies are considered, the model spread is reduced in a few regions, while the uncertainty can be increased in others. We also demonstrate that the common attribution of a lack of model agreement in precipitation projections to different model physics may be misleading. Agreement is similarly poor within different ensemble members of the same model, indicating that the lack of robust trends can be attributed partly to a low signal‐to‐noise ratio.

<div class="Citation-copy">
&copy; American Geophysical Union (AGU), 2011
</div>