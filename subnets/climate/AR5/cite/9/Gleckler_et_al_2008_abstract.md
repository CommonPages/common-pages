index: hide

<div class="Citation">
    <div class="Citation-thumb CitationThumb-linked"  data-href="https://doi.org/10.1029/2007jd008972">
      <img src="https://static.claimspace.cloud/climate-study-static/refs/thumbs/9/Gleckler_et_al_2008-thumb.png" />
    </div>

  <div class="Citation-body">
    <div class="Citation-text">Gleckler, PJ and Taylor, KE and Doutriaux, C, 2008: Performance metrics for climate models. <span class="Article-journal">Journal of Geophysical Research-Atmospheres, </span><span class="Article-volume">113, </span>D06104pp.</div>
    <div class="Citation-links">
      <div class="CitationLink" data-href="https://doi.org/10.1029/2007jd008972">
        <div class="CitationLink-icon CitationLink-Doi"></div>
        <div class="CitationLink-text">DOI</div>
      </div>
      <div class="CitationLink" data-href="https://scholar.google.com/scholar?q=10.1029/2007jd008972">
        <div class="CitationLink-icon CitationLink-Scholar"></div>
        <div class="CitationLink-text">Google Scholar</div>
      </div>
    </div>
  </div>
</div>

Objective measures of climate model performance are proposed and used to assess simulations of the 20th century, which are available from the Coupled Model Intercomparison Project (CMIP3) archive. The primary focus of this analysis is on the climatology of atmospheric fields. For each variable considered, the models are ranked according to a measure of relative error. Based on an average of the relative errors over all fields considered, some models appear to perform substantially better than others. Forming a single index of model performance, however, can be misleading in that it hides a more complex picture of the relative merits of different models. This is demonstrated by examining individual variables and showing that the relative ranking of models varies considerably from one variable to the next. A remarkable exception to this finding is that the so‐called “mean model” consistently outperforms all other models in nearly every respect. The usefulness, limitations and robustness of the metrics defined here are evaluated 1) by examining whether the information provided by each metric is correlated in any way with the others, and 2) by determining how sensitive the metrics are to such factors as observational uncertainty, spatial scale, and the domain considered (e.g., tropics versus extra‐tropics). An index that gauges the fidelity of model variability on interannual time‐scales is found to be only weakly correlated with an index of the mean climate performance. This illustrates the importance of evaluating a broad spectrum of climate processes and phenomena since accurate simulation of one aspect of climate does not guarantee accurate representation of other aspects. Once a broad suite of metrics has been developed to characterize model performance it may become possible to identify optimal subsets for various applications.

<div class="Citation-copy">
&copy; American Geophysical Union (AGU), 2008
</div>