index: hide
public: ar5-
name: Section 1.4.4
title: 1.4.4 - Uncertainty Treatment in This Assessment

All three IPCC Working Groups in the AR5 have agreed to use two metrics for communicating the degree of certainty in key findings ({cite.1.'Mastrandrea_et_al_2010}):

Confidence in the validity of a finding, based on the type, amount, quality, and consistency of evidence (e.g., data, mechanistic understanding, theory, models, expert judgment) and the degree of agreement. Confidence is expressed qualitatively.
Quantified measures of uncertainty in a finding expressed probabilistically (based on statistical analysis of observations or model results, or expert judgement).

A level of confidence synthesizes the Chapter teams’ judgements about the validity of findings as determined through evaluation of the available evidence and the degree of scientific agreement. The evidence and agreement scale underpins the assessment, as it is on the basis of evidence and agreement that statements can be made with scientific confidence (in this sense, the evidence and agreement scale replaces the ‘level of scientific understanding’ scale used in previous WGI assessments). There is flexibility in this relationship; for a given evidence and agreement statement, different confidence levels could be assigned, but increasing levels of evidence and degrees of agreement are correlated with increasing confidence. Confidence cannot necessarily be assigned for all combinations of evidence and agreement, but where key variables are highly uncertain, the available evidence and scientific agreement regarding that variable are presented and discussed. Confidence should not be interpreted probabilistically, and it is distinct from ‘statistical confidence’.

The confidence level is based on the evidence (robust, medium and limited) and the agreement (high, medium and low). A combination of different methods, e.g., observations and modelling, is important for evaluating the confidence level. {'Figure_1_11 Figure 1.11} shows how the combined evidence and agreement results in five levels for the confidence level used in this assessment.

{image:'Figure_1_11}

The qualifier ‘{Glossary.*Likelihood likelihood}’ provides calibrated language for describing quantified uncertainty. It can be used to express a probabilistic estimate of the occurrence of a single event or of an outcome, for example, a climate parameter, observed {Glossary.*Trend trend}, or {Topics.*Climate_Projections projected} change lying in a given range. Statements made using the likelihood scale may be based on statistical or modelling analyses, elicitation of expert views, or other quantitative analyses. Where sufficient information is available it is preferable to eschew the likelihood qualifier in favour of the full probability distribution or the appropriate probability range. See {'Table_1_2 Table 1.2} for the list of ‘likelihood’ qualifiers to be used in AR5.

Many social sciences studies have found that the interpretation of uncertainty is contingent on the presentation of information, the context within which statements are placed and the interpreter’s own lexical preferences. Readers often adjust their interpretation of probabilistic language according to the magnitude of perceived potential consequences ({cite.1.'Patt_and_Schrag_2003}; {cite.1.'Patt_and_Dessai_2005}). Furthermore, the framing of a probabilistic statement impinges on how it is interpreted ({cite.1.'Kahneman_and_Tversky_1979}): for example, a 10% chance of dying is interpreted more negatively than a 90% chance of surviving.

In addition, work examining expert judgement and decision making shows that people—including scientific experts—are prone to a range of heuristics and biases that affect their judgement (e.g., {cite.1.'Kahneman_et_al_1982}). For example, in the case of expert judgements there is a tendency towards overconfidence both at the individual level ({cite.1.'Morgan_et_al_1990}) and at the group level as people converge on a view and draw confidence in its reliability from each other. However, in an assessment of the state of scientific knowledge across a field such as climate change—characterized by complexity of process and heterogeneity of data constraints—some degree of expert judgement is inevitable ({cite.1.'Mastrandrea_et_al_2010}).

These issues were brought to the attention of chapter teams so that contributors to the AR5 might be sensitized to the ways presentation, framing, context and potential biases might affect their own assessments and might contribute to readers’ understanding of the information presented in this assessment. There will always be room for debate about how to summarize such a large and growing literature. The uncertainty guidance is aimed at providing a consistent, calibrated set of words through which to communicate the uncertainty, confidence and degree of consensus prevailing in the scientific literature. In this sense the guidance notes and practices adopted by IPCC for the presentation of {Topics.*Uncertainty uncertainties} should be regarded as an interdisciplinary work in progress, rather than as a finalized, comprehensive approach. Moreover, one precaution that should be considered is that translation of this assessment from English to other languages may lead to a loss of precision.
