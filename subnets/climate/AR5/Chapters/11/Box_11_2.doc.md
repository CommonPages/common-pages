index: hide
public: ar5-Box-11.2
name: Box 11.2
title: Box 11.2 - Ability of Climate Models to Simulate Observed Regional Trends

The ability of models to simulate {Topics.*Past_Climate past climate} change on regional scales can be used to investigate whether the multi-model {Glossary.*Ensemble ensemble} spread covers the forcing and model {Topics.*Uncertainty uncertainties}. Agreement between observed and simulated regional trends, taking natural variability and {Glossary.*Model_spread model spread} into account, would build confidence in near-term {Topics.*Climate_Projections projections}. Although large-scale features are simulated well (see {Chapters.10 Chapter 10}), on sub-continental and smaller scales the observed trends are, in general, more often in the tails of the distribution of modelled trends than would be expected by chance fluctuations ({cite.11.'Bhend_and_Whetton_2012}; Knutson et al., 2013b; van Oldenborgh et al., 2013). Natural variability and model spread are larger at smaller scales ({cite.11.'Stott_et_al_2010}), but this is not enough to bridge the gap between models and observations. {Glossary.*Downscaling Downscaling} with {Glossary.*Regional_Climate_Model Regional Climate Models} (RCMs) does not affect seasonal mean trends except near mountains or coastlines in Europe (van Oldenborgh et al., 2009; van Haren et al., 2012). These results hold for both observed and modelled estimates of natural variability and for various analyses of the observations. Given the statistical nature of the comparisons, it is currently not possible to say in which regions observed discrepancies are due to coincidental natural variability and in which regions they are due to forcing or model deficiencies. These results show that in general the Coupled {Topics.*Model_Intercomparison Model Intercomparison} Project Phase 5 (CMIP5) ensemble cannot be taken as a reliable regional probability forecast, but that the true uncertainty can be larger than the model spread indicated in the maps in this chapter and Annex I.

Temperature

Räisänen (2007) and {cite.11.'Yokohata_et_al_2012 Yokohata et al. (2012)} compared regional linear temperature trends during 1955–2005 (1961–2000) with corresponding trends in the CMIP3 ensemble. They found that the range of simulated trends captured the observed {Glossary.*Trend trend} in nearly all locations. Using another {Glossary.*Metric metric}, Knutson et al., (2013b) found that CMIP5 models did slightly better than CMIP3 in reproducing linear trends (see also {'Figure_10_2 Figure 10.2}, {Chapters.10.10_3.10_3_1.10_3_1_1.10_3_1_1_2 Section 10.3.1.1.2}). The linear CMIP5 temperature trends are compared with the observed trends in {Box_11_2 Box 11.2}, {'Box_11_2_Figure_1 Figure 1}a–h. The rank histograms show the warm bias in global mean temperature (see {Chapters.10 Chapter 10}) and some overconfidence, but within the inter-model spread. However, the apparent agreement appears to be for the wrong reason. Many of the models that appear to correctly simulate observed high regional trends do so because they have a high {Glossary.*Climate_response climate response} (i.e., the global temperature rises quickly) and do not simulate the observed spatial pattern of trends ({cite.11.'Kumar_et_al_2013}). To address this, {cite.11.'Bhend_and_Whetton_2012 Bhend and Whetton (2012)} and van Oldenborgh et al. (2013) use another definition of the local trend: the regression of the local temperature on the (low-pass filtered) global mean temperature. This definition separates the local temperature response pattern from the global mean climate response. They find highly significant discrepancies between the CMIP3 and CMIP5 trend patterns and a variety of estimates of observed trend estimates. These discrepancies are defined relative to an error model that includes the (modelled or observed) natural variability, model spread and spatial autocorrelations. In the following, areas where the observed and modelled trends show marked differences are noted. Areas of agreement are covered in {Chapters.10.10_3.10_3_1.10_3_1_1.10_3_1_1_4 Section 10.3.1.1.4}.

{image:'Box_11_2_Figure_1}

In December to February the observed Arctic amplification extends further south than modelled in Central Asia and northwestern North America. In June to August southern Europe and North Africa have warmed significantly faster than both CMIP3 and CMIP5 models simulated (van Oldenborgh et al., 2009); this also holds for the Middle East. The observed Indo-Pacific warm pool trend is significantly higher than the modelled trend year-round ({cite.11.'Shin_and_Sardeshmukh_2011}; {cite.11.'Williams_and_Funk_2011}), and the North Pacific and the southeastern USA and adjoining ocean trends were lower. Direct causes for many of these discrepancies are known (e.g., December to February circulation trends that differ between the observation and the models ({cite.11.'Gillett_et_al_2005}; {cite.11.'Gillett_and_Stott_2009}; van Oldenborgh et al., 2009; {cite.11.'Bhend_and_Whetton_2012}) or teleconnections from other areas with trend biases ({cite.11.'Deser_and_Phillips_2009}; {cite.11.'Meehl_et_al_2012a}), but the causes of the underlying discrepancies are often unknown. Possibilities include observational uncertainties (note, however, that the areas where the observations warm more than the models do not correspond to areas of increased urbanization or irrigation; cf. {Chapters.2.2_4.2_4_1.2_4_1_3 Section 2.4.1.3}), an underestimation of the low-frequency variability (Knutson et al. (2013b) show evidence that this is probably not the case for temperature outside the tropics), unrealistic local forcing (e.g., aerosols ({cite.11.'Ruckstuhl_and_Norris_2009})), or missing or misrepresented processes in models (e.g., fog ({cite.11.'Vautard_et_al_2009}; {cite.11.'Ceppi_et_al_2012})).

Precipitation

In spite of the larger variability relative to the trends and observational uncertainties (cf. {Chapters.2.2_5.2_5_1.2_5_1_2 Section 2.5.1.2}), annual mean regional linear precipitation trends have been found to differ significantly between observations and CMIP3 models, both in the zonal mean ({cite.11.'Allan_and_Soden_2007}; {cite.11.'Zhang_et_al_2007b}) and regionally (Räisänen, 2007). The comparison is shown in {Box_11_2 Box 11.2}, {'Box_11_2_Figure_1 Figure 1}i–p for the CMIP5 half-year seasons used in Annex I, following van Oldenborgh et al. (2013). In both half years the observations fall more often in the highest and lowest 5% than expected by chance fluctuations within the ensemble (grey area). The differences larger than the difference between the CRU and GPCC analyses (cf. {'Figure_2_29 Figure 2.29}) are noted below.

In Europe there are large-scale differences between observed trends and trends, both in General Circulation Models ({Glossary.*General_Circulation_Model GCMs}) and RCMs (Bhend and von Storch, 2008), which are ascribed to circulation change discrepancies in winter and in summer sea {Topics.*Surface_Temperature surface temperature} ({Glossary.*Sea_Surface_Temperature SST}) trend biases ({cite.11.'Lenderink_et_al_2009}; van Haren et al., 2012) and the misrepresentation of Summer North Atlantic Oscillation ({Glossary.*North_Atlantic_Oscillation NAO}) teleconnections (Bladé et al., 2012). Central North America has become much wetter over 1950–2012, especially in winter, which is not simulated by the CMIP5 models. Larger observed northwest Australian rainfall increases than in CMIP3 in summer are driven by {Glossary.*Ozone ozone} {Topics.*Radiative_Forcing forcings} in two {Topics.*Climate_Modelling climate models} ({cite.11.'Kang_et_al_2011}) and aerosols in another ({cite.11.'Rotstayn_et_al_2012}). The Guinea Coast has become drier in the observations than in the models. The CMIP5 patterns seem to reproduce the observed patterns somewhat better than the CMIP3 patterns ({cite.11.'Bhend_and_Whetton_2012}), but the remaining discrepancies imply that CMIP5 projections cannot be used as reliable precipitation forecasts.
